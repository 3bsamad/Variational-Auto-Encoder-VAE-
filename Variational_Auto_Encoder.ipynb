{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Variational Auto Encoder.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOLKXRD0GOYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################################################################################################\n",
        "#\n",
        "#\tVariational Auto Encoder Built using Keras and celebA dataset is used \n",
        "#\tfor training.\n",
        "#\t\n",
        "#\tCreated by : B V P Sai Kumar \n",
        "#\tgithub : https://github.com/kumararduino\n",
        "#\twebsite : https://kumarbasaveswara.in\n",
        "#\tlinkedin : https://www.linkedin.com/in/kumar15412304/\n",
        "#\n",
        "#\n",
        "#\tCredits:\n",
        "#\tDataset : https://www.kaggle.com/jessicali9530/celeba-dataset\n",
        "#\tArticle : https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf\n",
        "#\t\tThis Article gave me a clear glance about how Variational_Auto_Encoders work\n",
        "# Article on KL_Divergence : https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained\n",
        "#\t\n",
        "#\n",
        "#\n",
        "###############################################################################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMaCTHUODmXU",
        "colab_type": "text"
      },
      "source": [
        "Import Necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7Qcr3BWuXNc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "import psutil\n",
        "import multiprocessing as mp\n",
        "import copy\n",
        "mp.cpu_count()\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import keras\n",
        "from keras.models import Model,Sequential\n",
        "from keras.layers import Dense,Conv2D,MaxPooling2D,Dropout,BatchNormalization,Lambda,Activation,Input,Flatten,Reshape,Conv2DTranspose\n",
        "import keras.backend as K\n",
        "from keras.layers.merge import add\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import glob\n",
        "from time import time,asctime\n",
        "from random import randint as r\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SD-05aokD0k0",
        "colab_type": "text"
      },
      "source": [
        "Upload Kaggle api .json file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5m0idgIu7W1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q56X7gHTD3rv",
        "colab_type": "text"
      },
      "source": [
        "Download celeba dataset from kaggle and save to disk\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXnAITnGvAk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!ls ~/.kaggle\n",
        "!ls -l ~/.kaggle\n",
        "!cat ~/.kaggle/kaggle.json\n",
        "!pip install -q kaggle\n",
        "!pip install -q kaggle-cli\n",
        "os.mkdir(\"faces\")\n",
        "os.chdir(\"faces\")\n",
        "!kaggle datasets download -d jessicali9530/celeba-dataset\n",
        "!unzip celeba-dataset.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xNr_ls2vWvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip img_align_celeba.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrulpW1TD-aU",
        "colab_type": "text"
      },
      "source": [
        "Load file names of all pics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StjAD_cCvZ5l",
        "colab_type": "code",
        "outputId": "04682243-e90a-4dcc-87d4-f7853a152ecf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        }
      },
      "source": [
        "# os.chdir(\"faces\")\n",
        "imgs = glob.glob(\"img_align_celeba/*.jpg\")\n",
        "print(len(imgs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "202599\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdIhw6nuEBtt",
        "colab_type": "text"
      },
      "source": [
        "create Input vector of 200000 images each of shape (32,32,3) and scale them by dividing them by 255.save this as Y_data and also normalize the Y_data and save it as Z_data to train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbCYhpWPCIB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_y = []\n",
        "train_y2 = []\n",
        "for _ in range(0,100000):\n",
        "  if _%20000 == 0:\n",
        "    print(\"{} / 100000\".format(_))\n",
        "  img = cv2.imread(imgs[_])\n",
        "  img = cv2.resize(img,(32,32),interpolation = cv2.INTER_AREA)\n",
        "  train_y.append(img.astype(\"float32\")/255.0)\n",
        "for _ in range(100000,200000):\n",
        "  if _%20000 == 0:\n",
        "    print(\"{} / 200000\".format(_))\n",
        "  img = cv2.imread(imgs[_])\n",
        "  img = cv2.resize(img,(32,32),interpolation = cv2.INTER_AREA)\n",
        "  train_y2.append(img.astype(\"float32\")/255.0)\n",
        "train_y = np.array(train_y)\n",
        "train_y2 = np.array(train_y2)\n",
        "Y_data = np.vstack((train_y,train_y2))\n",
        "print(psutil.virtual_memory())\n",
        "del train_y,train_y2\n",
        "gc.collect()\n",
        "print(psutil.virtual_memory())\n",
        "Z_data = copy.deepcopy(Y_data)\n",
        "Z_data = (Z_data - Z_data.mean())/Z_data.std()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwZ3vkCpEciP",
        "colab_type": "text"
      },
      "source": [
        "This is the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2bhja5qCHzk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_Y = []\n",
        "for _ in range(200000,202599):\n",
        "  if _%5000 == 0:\n",
        "    print(\"{} / 100000\".format(_))\n",
        "  img = cv2.imread(imgs[_])\n",
        "  img = cv2.resize(img,(32,32),interpolation = cv2.INTER_AREA)\n",
        "  test_Y.append(img.astype(\"float32\")/255.0)\n",
        "  \n",
        "test_Y = np.array(test_Y)\n",
        "mean = test_Y.mean()\n",
        "std = test_Y.std()\n",
        "test_Z = (test_Y - mean)/std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn4aeJp6Egq6",
        "colab_type": "text"
      },
      "source": [
        "Variational Auto Encoder has a sampler \n",
        "In VAE, the encoder outputs two vectors.one is mean and the other is standard_deviation.sample from these two\n",
        "are taken as a final vector that can be done using the **sampler** function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orb_K5T77-7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sampler(layers):\n",
        "  std_norm = K.random_normal(shape=(K.shape(layers[0])[0], 64), mean=0, stddev=1)\n",
        "  return layers[0] + K.log(layers[1])*std_norm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJMas-okFD-n",
        "colab_type": "text"
      },
      "source": [
        "Building the **Encoder** part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cERc9buwBaTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stride = 2\n",
        "inp = Input(shape = (32,32,3))\n",
        "x = inp\n",
        "x = Conv2D(32,(2,2),strides = stride,activation = \"relu\",padding = \"same\")(x)\n",
        "x = Conv2D(64,(2,2),strides = stride,activation = \"relu\",padding = \"same\")(x)\n",
        "x = Conv2D(128,(2,2),strides = stride,activation = \"relu\",padding = \"same\")(x)\n",
        "shape = K.int_shape(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(256,activation = \"relu\")(x)\n",
        "mean_layer = Dense(128,activation = \"relu\")(x)\n",
        "sd_layer = Dense(128,activation = \"relu\")(x)\n",
        "latent_vector = Lambda(sampler)([mean_layer,sd_layer])\n",
        "encoder = Model(inp,latent_vector,name = \"VAE_Encoder\")\n",
        "encoder.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIuoo_-eFJXl",
        "colab_type": "text"
      },
      "source": [
        "Building the **Decoder** part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7qUl9JfBaQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_inp = Input(shape = (128,))\n",
        "x = decoder_inp\n",
        "x = Dense(shape[1]*shape[2]*shape[3],activation = \"relu\")(x)\n",
        "x = Reshape((shape[1],shape[2],shape[3]))(x)\n",
        "x = (Conv2DTranspose(32,(3,3),strides = stride,activation = \"relu\",padding = \"same\"))(x)\n",
        "x = (Conv2DTranspose(16,(3,3),strides = stride,activation = \"relu\",padding = \"same\"))(x)\n",
        "x = (Conv2DTranspose(8,(3,3),strides = stride,activation = \"relu\",padding = \"same\"))(x)\n",
        "outputs = Conv2DTranspose(3, (3,3), activation = 'sigmoid', padding = 'same', name = 'decoder_output')(x)\n",
        "decoder = Model(decoder_inp,outputs,name = \"VAE_Decoder\")\n",
        "decoder.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-6BNcyaFRji",
        "colab_type": "text"
      },
      "source": [
        "Connecting the Encoder and Decoder to make the **Auto Encoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8KbxzMxBaOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder = Model(inp,decoder(encoder(inp)),name = \"Variational_Auto_Encoder\")\n",
        "autoencoder.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ierKRKACFYbI",
        "colab_type": "text"
      },
      "source": [
        "This is the loss function used by the VAE.It is calculating KL_Divergence loss.KL-Divergence is explained clearly in this article\n",
        "[KL-Divergence](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHGAu5oGBaMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vae_loss(input_img, output):\n",
        "\t# compute the average MSE error, then scale it up, ie. simply sum on all axes\n",
        "\treconstruction_loss = K.sum(K.square(output-input_img))\n",
        "\t# compute the KL loss\n",
        "\tkl_loss = - 0.5 * K.sum(1 + sd_layer - K.square(mean_layer) - K.square(K.exp(sd_layer)), axis=-1)\n",
        "\t# return the average loss over all images in batch\n",
        "\ttotal_loss = K.mean(reconstruction_loss + kl_loss)    \n",
        "\treturn total_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2R5_XH6BaKV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder.compile(optimizer = \"adam\",loss = vae_loss,metrics = [\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rm6u84OSF1OW",
        "colab_type": "text"
      },
      "source": [
        "Training the VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrIay3BKBaIa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder.fit(Z_data,Y_data,batch_size = 200,epochs = 50,validation_split = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O_1hWqzBaGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = autoencoder.predict(test_Z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DycMIFGgF4To",
        "colab_type": "text"
      },
      "source": [
        "Displaying the input,normalized input,VAE output "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTqpsXWbBaD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp = r(0,2599)\n",
        "print(temp)\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(test_Y[temp])\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(test_Z[temp])\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(pred[temp])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTeMxYm6F99-",
        "colab_type": "text"
      },
      "source": [
        "Generating a new face by passing a random normal sample of size (32,32,3) and observing the output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVpaLlSbB9UQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen = np.random.normal(size = (1,32,32,3))\n",
        "gen_sample = autoencoder.predict(gen)\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(gen[0])\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(gen_sample[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TmgLCJqGHZu",
        "colab_type": "text"
      },
      "source": [
        "Saving the model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1Mqdk3IB83a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder.save_weights(\"VAE-weights-\"+asctime()+\".h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}